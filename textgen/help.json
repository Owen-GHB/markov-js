{
  "generate": {
    "description": "Generate text from a trained model",
    "syntax": "generate(modelName, [options])",
    "examples": [
      "generate(\"model.json\", length=50, temperature=0.8)",
      "generate({modelName: \"story_model.json\", prompt: \"Once upon a time\"})"
    ],
    "parameters": {
      "modelName": {
        "description": "Model file to use for generation"
      },
      "length": {
        "description": "Maximum number of tokens to generate"
      },
      "min_tokens": {
        "description": "Minimum number of tokens to generate"
      },
      "temperature": {
        "description": "Randomness factor (lower = more predictable)"
      },
      "prompt": {
        "description": "Starting text for generation"
      },
      "stop": {
        "description": "Stop tokens that end generation"
      },
      "samples": {
        "description": "Number of samples to generate"
      },
      "allowRepetition": {
        "description": "Allow immediate token repetition"
      }
    }
  },
  "train": {
    "description": "Train a model from a text corpus file",
    "syntax": "train(file, modelType, [options])",
    "examples": [
      "train(\"sample.txt\", \"markov\", order=2)",
      "train({file: \"corpus.txt\", modelType: \"vlmm\", order: 3})"
    ],
    "parameters": {
      "file": {
        "description": "Corpus file to train from"
      },
      "modelType": {
        "description": "Type of model to train"
      },
      "order": {
        "description": "Markov order (n-gram size)"
      },
      "modelName": {
        "description": "Filename to save the trained model"
      },
      "caseSensitive": {
        "description": "Whether to preserve case during tokenization"
      },
      "trackStartStates": {
        "description": "Whether to track sentence start states"
      }
    }
  }
}