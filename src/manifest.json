{
	"name": "markov-text-generator",
	"version": "1.0.0",
	"description": "Markov chain text generation engine with multiple model types",
	"stateDefaults": {
		"currentModel": null,
		"defaultCorpus": "sample.txt"
	},
	"commands": [
		{
			"name": "train",
			"description": "Train a model from a text corpus file",
			"syntax": "train(file, modelType, [options])",
			"parameters": [
				{
					"name": "file",
					"type": "string",
					"required": true,
					"description": "Corpus file to train from",
					"runtimeFallback": "defaultCorpus"
				},
				{
					"name": "modelType",
					"type": "string",
					"required": true,
					"enum": ["markov", "vlmm", "hmm"],
					"description": "Type of model to train"
				},
				{
					"name": "order",
					"type": "integer",
					"required": false,
					"default": 2,
					"min": 1,
					"max": 10,
					"description": "Markov order (n-gram size)"
				},
				{
					"name": "modelName",
					"type": "string",
					"required": false,
					"kind": "implicit",
					"description": "Filename to save the trained model"
				},
				{
					"name": "caseSensitive",
					"type": "boolean",
					"required": false,
					"default": false,
					"description": "Whether to preserve case during tokenization"
				},
				{
					"name": "trackStartStates",
					"type": "boolean",
					"required": false,
					"default": true,
					"description": "Whether to track sentence start states"
				}
			],
			"sideEffects": {
				"setState": {
					"currentModel": {
						"fromParam": "modelName",
						"template": "{{file | basename}}.json"
					}
				}
			},
			"examples": [
				"train(\"sample.txt\", \"markov\", order=2)",
				"train({file: \"corpus.txt\", modelType: \"vlmm\", order: 3})"
			]
		},
		{
			"name": "generate",
			"description": "Generate text from a trained model",
			"syntax": "generate(modelName, [options])",
			"parameters": [
				{
					"name": "modelName",
					"type": "string",
					"required": true,
					"description": "Model file to use for generation",
					"runtimeFallback": "currentModel"
				},
				{
					"name": "length",
					"type": "integer",
					"required": false,
					"default": 100,
					"min": 1,
					"description": "Maximum number of tokens to generate"
				},
				{
					"name": "min_tokens",
					"type": "integer",
					"required": false,
					"default": 50,
					"min": 1,
					"description": "Minimum number of tokens to generate"
				},
				{
					"name": "temperature",
					"type": "number",
					"required": false,
					"default": 1.0,
					"min": 0.0,
					"max": 2.0,
					"description": "Randomness factor (lower = more predictable)"
				},
				{
					"name": "prompt",
					"type": "string",
					"required": false,
					"description": "Starting text for generation"
				},
				{
					"name": "stop",
					"type": "array",
					"required": false,
					"default": [".", "!", "?"],
					"description": "Stop tokens that end generation"
				},
				{
					"name": "samples",
					"type": "integer",
					"required": false,
					"default": 1,
					"min": 1,
					"description": "Number of samples to generate"
				},
				{
					"name": "allowRepetition",
					"type": "boolean",
					"required": false,
					"default": true,
					"description": "Allow immediate token repetition"
				}
			],
			"sideEffects": {
				"setState": {
					"currentModel": { "fromParam": "modelName" }
				}
			},
			"examples": [
				"generate(\"model.json\", length=50, temperature=0.8)",
				"generate({modelName: \"story_model.json\", prompt: \"Once upon a time\"})"
			]
		},
		{
			"name": "listModels",
			"description": "List all available saved models",
			"syntax": "listModels()",
			"parameters": [],
			"examples": ["listModels()"]
		},
		{
			"name": "listCorpus",
			"description": "List all available corpus files",
			"syntax": "listCorpus()",
			"parameters": [],
			"examples": ["listCorpus()"]
		},
		{
			"name": "delete",
			"description": "Delete a saved model",
			"syntax": "delete(modelName)",
			"parameters": [
				{
					"name": "modelName",
					"type": "string",
					"required": true,
					"description": "Name of the model file to delete"
				}
			],
			"sideEffects": {
				"clearStateIf": {
					"currentModel": { "fromParam": "modelName" }
				}
			},
			"examples": ["delete(\"old_model.json\")"]
		},
		{
			"name": "use",
			"description": "Set the current model to use",
			"syntax": "use(modelName)",
			"parameters": [
				{
					"name": "modelName",
					"type": "string",
					"required": true,
					"description": "Name of the model to set as current",
					"runtimeFallback": "currentModel"
				}
			],
			"sideEffects": {
				"setState": {
					"currentModel": { "fromParam": "modelName" }
				}
			},
			"examples": ["use(\"current_model.json\")"]
		},
		{
			"name": "pgb_search",
			"description": "Search Project Gutenberg by title/author",
			"syntax": "pgb_search(query)",
			"parameters": [
				{
					"name": "query",
					"type": "string",
					"required": true,
					"description": "Search query for Project Gutenberg"
				}
			],
			"examples": ["pgb_search(\"Sherlock Holmes\")"]
		},
		{
			"name": "pgb_info",
			"description": "Get book details from Project Gutenberg",
			"syntax": "pgb_info(id_or_title)",
			"parameters": [
				{
					"name": "id_or_title",
					"type": "string|integer",
					"required": true,
					"description": "Book ID or title to get information about",
					"transform": {
						"if": "integer",
						"then": { "id": "value" },
						"else": { "title": "value" }
					}
				}
			],
			"examples": [
				"pgb_info(1342)",
				"pgb_info(\"Pride and Prejudice\")",
				"pgb_info({id: 1342})",
				"pgb_info({title: \"Pride and Prejudice\"})"
			]
		},
		{
			"name": "pgb_download",
			"description": "Download a book from Project Gutenberg",
			"syntax": "pgb_download(id|title, [options])",
			"parameters": [
				{
					"name": "id_or_title",
					"type": "string|integer",
					"required": true,
					"description": "Book ID or title to download",
					"transform": {
						"if": "integer",
						"then": { "id": "value" },
						"else": { "title": "value" }
					}
				},
				{
					"name": "file",
					"type": "string",
					"required": false,
					"description": "Filename to save the downloaded text",
					"default": null
				}
			],
			"examples": [
				"pgb_download(1342)",
				"pgb_download(\"Moby Dick\", file=\"whale.txt\")"
			]
		},
		{
			"name": "help",
			"description": "Show help information",
			"syntax": "help([command])",
			"parameters": [
				{
					"name": "command",
					"type": "string",
					"required": false,
					"description": "Specific command to get help for"
				}
			],
			"examples": ["help()", "help(\"generate\")"]
		},
		{
			"name": "exit",
			"description": "Exit the program",
			"syntax": "exit()",
			"parameters": [],
			"sideEffects": {
				"builtin": "exit"
			},
			"examples": ["exit()"]
		}
	],
	"syntaxPatterns": [
		{
			"name": "functionStyle",
			"pattern": "command(param1, param2, key=value)",
			"description": "Function-style syntax with positional and named parameters"
		},
		{
			"name": "objectStyle",
			"pattern": "command({param1: value, key: value})",
			"description": "Object-style syntax with all parameters as key-value pairs"
		},
		{
			"name": "simpleStyle",
			"pattern": "command",
			"description": "Simple command without parameters"
		},
		{
			"name": "cliStyle",
			"pattern": "command param1 param2 key=value",
			"description": "CLI-style syntax with space-separated parameters"
		}
	],
	"modelTypes": [
		{
			"name": "markov",
			"description": "Standard Markov chain model with fixed-order n-grams",
			"capabilities": {
				"supportsTemperature": true,
				"supportsConstraints": true,
				"supportsConditionalGeneration": true,
				"supportsBatchGeneration": true,
				"maxOrder": 10
			}
		},
		{
			"name": "vlmm",
			"description": "Variable-Length Markov Model with adaptive context length",
			"capabilities": {
				"supportsTemperature": true,
				"supportsConstraints": false,
				"supportsConditionalGeneration": true,
				"supportsBatchGeneration": true,
				"maxOrder": 10
			}
		},
		{
			"name": "hmm",
			"description": "Hidden Markov Model with state-based generation",
			"capabilities": {
				"supportsTemperature": false,
				"supportsConstraints": true,
				"supportsConditionalGeneration": true,
				"supportsBatchGeneration": true,
				"maxOrder": 1,
				"supportsUnsupervisedLearning": true
			}
		}
	],
	"filePaths": {
		"defaultCorpusDir": "./data/corpus",
		"defaultModelDir": "./data/models",
		"supportedCorpusExtensions": [".txt", ".md", ".csv"]
	}
}
